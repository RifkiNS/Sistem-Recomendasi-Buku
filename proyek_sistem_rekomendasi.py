# -*- coding: utf-8 -*-
"""Proyek Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qA1CQ1CxN490kIZqY5Z_JbiRXPtKmode

### IMPORT LIBRARY YANG DIGUNAKAN ###
Pada tahap ini melakukan import library python yang akan digunakan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.optimizers import Adam
import kagglehub

"""### MENDOWNLOAD DATASET DARI KAGGLE ###
Pada tahap ini adalah mendownload dataset yang berasal dari https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset menggunakan library kagglehub
"""

# Download latest version
path = kagglehub.dataset_download("arashnic/book-recommendation-dataset")

print("Path to dataset files:", path)

"""### MELOAD DATASET YANG SUDAH DIDOWNLOAD ###
Tahap ini membuat variabel df_book. df_rating dan df_user untuk melakukan load dataset yang telah didownload
"""

df_book = pd.read_csv(path + '/Books.csv')
df_rating = pd.read_csv(path + '/Ratings.csv')
df_user = pd.read_csv(path + '/Users.csv')

"""### UNIVARIATE EXPLORATORY DATA ANALYSIS ###
Tahap ini dilakukan untuk memahami variabel-variabel pada dataset dan memeriksa missing value serta tipe data pada dataset yang digunakan

Eksplorasi variabel df_book
"""

df_book.head()

"""info() digunakan untuk melihat tipe data pada dataset"""

df_book.info()

"""isna() untuk mengecek missing value pada kolom sedangkan sum() untuk menghitung jumlah missing value pada kolom. Pada dataset df_book terdapat missing value di kolom Book-Author, Publisher dan Image-URL-L"""

df_book.isnull().sum()

"""Eksplorasi variabel df_rating"""

df_rating.head()

"""info() digunakan untuk melihat tipe data pada dataset"""

df_rating.info()

"""isna() untuk mengecek missing value pada kolom sedangkan sum() untuk menghitung jumlah missing value pada kolom. Pada dataset df_rating tidak ada missing value"""

df_rating.isnull().sum()

"""Eksplorasi variabel df_user"""

df_user.head()

"""info() digunakan untuk melihat tipe data pada dataset"""

df_user.info()

"""isna() untuk mengecek missing value pada kolom sedangkan sum() untuk menghitung jumlah missing value pada kolom. Pada dataset df_user terdapat missing value di kolom Age."""

df_user.isnull().sum()

"""### DATA PROCESSING ###
Tahap ini dilakukan untuk memproses dataset sebelum dilakukan modekung. Mulai dari penggabungan dataset yang digunakan dan filtering dataset

merge() digunakan untuk menggabungkan dataset rating dengan dataset book berdasarkan ISBN
"""

df_all = df_rating.merge(df_book, on='ISBN')
df_all.head()

"""melakukan filtering terhadap kolom Book-Rating agar rating sama dengan 0 akan dibuang"""

df_all = df_all[df_all['Book-Rating'] > 0]

"""### DATA PREPARATION ###
Tahap ini dilakukan dengan beberapa proses mulai dari menangani missing value, meencode dataset, menghitung jumlah unik dan melakukan splitting dataset

dropna() digunakan untuk menghilangkan missing value pada dataset
"""

df_all = df_all.dropna()

"""LabelEncoder() meencode atau merubah dataset kategorik menjadi numerik"""

user_encoder = LabelEncoder()
item_encoder = LabelEncoder()

df_all['user'] = user_encoder.fit_transform(df_all['User-ID'])
df_all['item'] = item_encoder.fit_transform(df_all['Book-Title'])

"""nunique() digunakan untuk menghitung jumalah data unik pada kolom user dan item"""

num_users = df_all['user'].nunique()
num_items = df_all['item'].nunique()

"""merubah Book-Rating suka (rating =>7) = 1, tidak suka (rating <7) = 0"""

df_all['liked'] = df_all['Book-Rating'].apply(lambda x: 1 if x >= 7 else 0)

"""membagi dataset menjadi train dan test"""

X = df_all[['user', 'item']].values
y = df_all['liked'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### MODEL DEVOLEPMENT DENGAN COLLABORATIVE FILTERING ###
Tahap yang dilakukan untuk melatih model

membuat class model RecomenderClassifier dengan keras model class
"""

class RecommenderClassifier(tf.keras.Model):
    def __init__(self, num_users, num_items, embedding_size=50, **kwargs):
        super(RecommenderClassifier, self).__init__(**kwargs)
        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_size)
        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_size)
        self.dense = tf.keras.layers.Dense(64, activation='relu')
        self.output_layer = tf.keras.layers.Dense(1, activation='sigmoid')

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        item_vector = self.item_embedding(inputs[:, 1])
        x = tf.concat([user_vector, item_vector], axis=1)
        x = self.dense(x)
        output = self.output_layer(x)
        return output

"""melakukan compile pada model. Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan accuracy sebagai metrics evaluation karena proyek ini membuat model klasifikasi untuk memprediksi suka/tidak user."""

model = RecommenderClassifier(num_users, num_items)

model.compile(
    loss='binary_crossentropy',
    optimizer=Adam(learning_rate=0.001),
    metrics=['accuracy']
)

"""proses training model menggunakan 10 epochs"""

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=10,
    batch_size=256
)

"""visualiasasi proses training dengan memplot metrik evaluasi dengan matplotlib. hasil yang didapatkan model yang dibuat masih overfitting yang artinya model tidak belajr dengan baik pada data test."""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

def recommend_top_n(user_id, n=5):

    user_encoded = user_encoder.transform([user_id])
    all_items = np.array(range(num_items)).reshape(-1,1)
    user_input = np.column_stack((np.repeat(user_encoded, num_items), all_items.flatten()))
    probabilities = model.predict(user_input)

    # Create a DataFrame for recommendations
    recommendations = pd.DataFrame({'item': all_items.flatten(), 'probability': probabilities.flatten()})

    # Decode items back to book titles
    recommendations['Book-Title'] = item_encoder.inverse_transform(recommendations['item'])

    # Sort by probability and get top N
    top_recommendations = recommendations.sort_values('probability', ascending=False).head(n)

    return top_recommendations[['Book-Title', 'probability']]

# Example usage:
user_id_to_recommend = '276726' # Example user ID, replace with your desired user
recommendations = recommend_top_n(user_id_to_recommend, n=5)
recommendations